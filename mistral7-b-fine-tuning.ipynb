{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5112,"sourceType":"modelInstanceVersion","modelInstanceId":3900}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-14T03:38:41.524172Z","iopub.execute_input":"2024-05-14T03:38:41.525028Z","iopub.status.idle":"2024-05-14T03:38:41.873656Z","shell.execute_reply.started":"2024-05-14T03:38:41.524992Z","shell.execute_reply":"2024-05-14T03:38:41.872662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n%pip install -U bitsandbytes\n%pip install -U transformers\n%pip install -U peft\n%pip install -U accelerate\n%pip install -U trl ","metadata":{"execution":{"iopub.status.busy":"2024-05-14T03:38:45.826532Z","iopub.execute_input":"2024-05-14T03:38:45.827659Z","iopub.status.idle":"2024-05-14T03:40:07.305176Z","shell.execute_reply.started":"2024-05-14T03:38:45.827618Z","shell.execute_reply":"2024-05-14T03:40:07.304062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline, logging","metadata":{"execution":{"iopub.status.busy":"2024-05-14T03:42:41.146493Z","iopub.execute_input":"2024-05-14T03:42:41.146879Z","iopub.status.idle":"2024-05-14T03:42:57.881060Z","shell.execute_reply.started":"2024-05-14T03:42:41.146849Z","shell.execute_reply":"2024-05-14T03:42:57.880278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model","metadata":{"execution":{"iopub.status.busy":"2024-05-14T03:43:05.467219Z","iopub.execute_input":"2024-05-14T03:43:05.468193Z","iopub.status.idle":"2024-05-14T03:43:05.591302Z","shell.execute_reply.started":"2024-05-14T03:43:05.468156Z","shell.execute_reply":"2024-05-14T03:43:05.590544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os,torch,wandb","metadata":{"execution":{"iopub.status.busy":"2024-05-14T03:43:09.112479Z","iopub.execute_input":"2024-05-14T03:43:09.113183Z","iopub.status.idle":"2024-05-14T03:43:09.744559Z","shell.execute_reply.started":"2024-05-14T03:43:09.113152Z","shell.execute_reply":"2024-05-14T03:43:09.743530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2024-05-14T03:43:11.910406Z","iopub.execute_input":"2024-05-14T03:43:11.911026Z","iopub.status.idle":"2024-05-14T03:43:12.300612Z","shell.execute_reply.started":"2024-05-14T03:43:11.910975Z","shell.execute_reply":"2024-05-14T03:43:12.299819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from trl import SFTTrainer","metadata":{"execution":{"iopub.status.busy":"2024-05-14T03:43:14.799511Z","iopub.execute_input":"2024-05-14T03:43:14.800890Z","iopub.status.idle":"2024-05-14T03:43:14.838426Z","shell.execute_reply.started":"2024-05-14T03:43:14.800844Z","shell.execute_reply":"2024-05-14T03:43:14.837506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_hf = user_secrets.get_secret(\"DF_TOKEN\")\nsecret_wandb = user_secrets.get_secret(\"secret_wandb\")","metadata":{"execution":{"iopub.status.busy":"2024-05-14T03:43:17.994332Z","iopub.execute_input":"2024-05-14T03:43:17.994752Z","iopub.status.idle":"2024-05-14T03:43:18.354887Z","shell.execute_reply.started":"2024-05-14T03:43:17.994723Z","shell.execute_reply":"2024-05-14T03:43:18.353941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!huggingface-cli login --token $secret_hf","metadata":{"execution":{"iopub.status.busy":"2024-05-14T03:43:28.499712Z","iopub.execute_input":"2024-05-14T03:43:28.500366Z","iopub.status.idle":"2024-05-14T03:43:30.004862Z","shell.execute_reply.started":"2024-05-14T03:43:28.500322Z","shell.execute_reply":"2024-05-14T03:43:30.003912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Monitering the LLM\nwandb.login (key = secret_wandb)\nrun = wandb.init(\n    project='Fine-Tuning Mistral Instruct 7B', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T03:43:41.167602Z","iopub.execute_input":"2024-05-14T03:43:41.167983Z","iopub.status.idle":"2024-05-14T03:44:00.645191Z","shell.execute_reply.started":"2024-05-14T03:43:41.167947Z","shell.execute_reply":"2024-05-14T03:44:00.644151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mistralai\nbase_model = \"mistralai/7b-instruct-v0.1-hf\"","metadata":{"execution":{"iopub.status.busy":"2024-05-14T03:44:16.021814Z","iopub.execute_input":"2024-05-14T03:44:16.022467Z","iopub.status.idle":"2024-05-14T03:44:16.027833Z","shell.execute_reply.started":"2024-05-14T03:44:16.022432Z","shell.execute_reply":"2024-05-14T03:44:16.026723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = \"/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1\"\ndataset_name = \"mlabonne/guanaco-llama2-1k\"\nnew_model = \"mistral_7b-instruct-guanaco\"","metadata":{"execution":{"iopub.status.busy":"2024-05-14T03:44:20.198708Z","iopub.execute_input":"2024-05-14T03:44:20.199325Z","iopub.status.idle":"2024-05-14T03:44:20.204378Z","shell.execute_reply.started":"2024-05-14T03:44:20.199296Z","shell.execute_reply":"2024-05-14T03:44:20.203257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Importing the dataset\ndataset = load_dataset(dataset_name, split=\"train\")\ndataset[\"text\"][100]","metadata":{"execution":{"iopub.status.busy":"2024-05-14T03:44:23.392477Z","iopub.execute_input":"2024-05-14T03:44:23.393434Z","iopub.status.idle":"2024-05-14T03:44:27.553788Z","shell.execute_reply.started":"2024-05-14T03:44:23.393392Z","shell.execute_reply":"2024-05-14T03:44:27.552674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load base model(Mistral 7B)\nbnb_config = BitsAndBytesConfig(  \n    load_in_4bit= True,\n    bnb_4bit_quant_type= \"nf4\",\n    bnb_4bit_compute_dtype= torch.bfloat16,\n    bnb_4bit_use_double_quant= False,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T03:44:29.836418Z","iopub.execute_input":"2024-05-14T03:44:29.836768Z","iopub.status.idle":"2024-05-14T03:44:29.844599Z","shell.execute_reply.started":"2024-05-14T03:44:29.836740Z","shell.execute_reply":"2024-05-14T03:44:29.843463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q git+https://github.com/huggingface/transformers","metadata":{"execution":{"iopub.status.busy":"2024-05-14T03:44:33.781488Z","iopub.execute_input":"2024-05-14T03:44:33.782164Z","iopub.status.idle":"2024-05-14T03:45:20.326076Z","shell.execute_reply.started":"2024-05-14T03:44:33.782132Z","shell.execute_reply":"2024-05-14T03:45:20.324494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import kagglehub","metadata":{"execution":{"iopub.status.busy":"2024-05-14T03:45:41.599269Z","iopub.execute_input":"2024-05-14T03:45:41.600129Z","iopub.status.idle":"2024-05-14T03:45:41.633206Z","shell.execute_reply.started":"2024-05-14T03:45:41.600086Z","shell.execute_reply":"2024-05-14T03:45:41.632328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download latest version\npath = kagglehub.model_download(\"mistral-ai/mistral/pyTorch/7b-instruct-v0.1-hf\")\n\nprint(\"Path to model files:\", path)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T03:45:44.631125Z","iopub.execute_input":"2024-05-14T03:45:44.631945Z","iopub.status.idle":"2024-05-14T03:45:45.175220Z","shell.execute_reply.started":"2024-05-14T03:45:44.631910Z","shell.execute_reply":"2024-05-14T03:45:45.174040Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n        base_model,\n        quantization_config=bnb_config,\n        torch_dtype=torch.bfloat16,\n        device_map=\"auto\",\n        trust_remote_code=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T03:45:51.419697Z","iopub.execute_input":"2024-05-14T03:45:51.420083Z","iopub.status.idle":"2024-05-14T03:48:38.453582Z","shell.execute_reply.started":"2024-05-14T03:45:51.420052Z","shell.execute_reply":"2024-05-14T03:48:38.452437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    model = AutoModelForCausalLM.from_pretrained(\n        base_model,\n        quantization_config=bnb_config,\n        torch_dtype=torch.bfloat16,\n        device_map=\"auto\",\n        trust_remote_code=True,\n    )\n    print(\"Model loaded successfully!\")\nexcept Exception as e:\n    print(\"Failed to load model:\", str(e))","metadata":{"execution":{"iopub.status.busy":"2024-05-14T03:48:44.364675Z","iopub.execute_input":"2024-05-14T03:48:44.365729Z","iopub.status.idle":"2024-05-14T03:48:52.712568Z","shell.execute_reply.started":"2024-05-14T03:48:44.365684Z","shell.execute_reply":"2024-05-14T03:48:52.711618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.config.use_cache = False # silence the warnings. Please re-enable for inference!\nmodel.config.pretraining_tp = 1\nmodel.gradient_checkpointing_enable()\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\ntokenizer.padding_side = 'right'\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.add_eos_token = True\ntokenizer.add_bos_token, tokenizer.add_eos_token","metadata":{"execution":{"iopub.status.busy":"2024-05-14T03:48:57.294258Z","iopub.execute_input":"2024-05-14T03:48:57.294632Z","iopub.status.idle":"2024-05-14T03:48:57.424220Z","shell.execute_reply.started":"2024-05-14T03:48:57.294605Z","shell.execute_reply":"2024-05-14T03:48:57.423058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Adding the adapters in the layers\nmodel = prepare_model_for_kbit_training(model)\npeft_config = LoraConfig(\n    lora_alpha=16,\n    lora_dropout=0.1,\n    r=64,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"]\n)\nmodel = get_peft_model(model, peft_config)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T03:49:03.077114Z","iopub.execute_input":"2024-05-14T03:49:03.077990Z","iopub.status.idle":"2024-05-14T03:49:04.515862Z","shell.execute_reply.started":"2024-05-14T03:49:03.077956Z","shell.execute_reply":"2024-05-14T03:49:04.514680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hyperparamter\ntraining_arguments = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=1,\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=1,\n    optim=\"paged_adamw_32bit\",\n    save_steps=25,\n    logging_steps=25,\n    learning_rate=2e-4,\n    weight_decay=0.001,\n    fp16=False,\n    bf16=False,\n    max_grad_norm=0.3,\n    max_steps=-1,\n    warmup_ratio=0.03,\n    group_by_length=True,\n     lr_scheduler_type=\"constant\",\n    report_to=\"wandb\"\n    )","metadata":{"execution":{"iopub.status.busy":"2024-05-14T03:49:10.491847Z","iopub.execute_input":"2024-05-14T03:49:10.492236Z","iopub.status.idle":"2024-05-14T03:49:10.523722Z","shell.execute_reply.started":"2024-05-14T03:49:10.492205Z","shell.execute_reply":"2024-05-14T03:49:10.522247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting sft parameters\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset,\n    peft_config=peft_config,\n    max_seq_length= None,\n    dataset_text_field=\"text\",\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing= False,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T03:49:15.122775Z","iopub.execute_input":"2024-05-14T03:49:15.123526Z","iopub.status.idle":"2024-05-14T03:49:15.814273Z","shell.execute_reply.started":"2024-05-14T03:49:15.123494Z","shell.execute_reply":"2024-05-14T03:49:15.812946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-14T03:49:23.021878Z","iopub.execute_input":"2024-05-14T03:49:23.022890Z","iopub.status.idle":"2024-05-14T04:38:19.086063Z","shell.execute_reply.started":"2024-05-14T03:49:23.022847Z","shell.execute_reply":"2024-05-14T04:38:19.084997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.model.save_pretrained(\"/kaggle/working/models/new_model\")","metadata":{"execution":{"iopub.status.busy":"2024-05-14T05:31:27.977890Z","iopub.execute_input":"2024-05-14T05:31:27.978316Z","iopub.status.idle":"2024-05-14T05:31:28.546457Z","shell.execute_reply.started":"2024-05-14T05:31:27.978284Z","shell.execute_reply":"2024-05-14T05:31:28.545146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the fine-tuned model\ntrainer.model.save_pretrained(new_model)\nwandb.finish()\nmodel.config.use_cache = True\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2024-05-14T05:31:43.905553Z","iopub.execute_input":"2024-05-14T05:31:43.905899Z","iopub.status.idle":"2024-05-14T05:31:50.522759Z","shell.execute_reply.started":"2024-05-14T05:31:43.905874Z","shell.execute_reply":"2024-05-14T05:31:50.521867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.model.push_to_hub(\"SajidaAB/mistral-ai-7b\", use_temp_dir=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T06:15:07.021135Z","iopub.execute_input":"2024-05-14T06:15:07.021882Z","iopub.status.idle":"2024-05-14T06:15:07.282081Z","shell.execute_reply.started":"2024-05-14T06:15:07.021850Z","shell.execute_reply":"2024-05-14T06:15:07.280871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logging.set_verbosity(logging.CRITICAL)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T06:15:11.955628Z","iopub.execute_input":"2024-05-14T06:15:11.956304Z","iopub.status.idle":"2024-05-14T06:15:11.961663Z","shell.execute_reply.started":"2024-05-14T06:15:11.956273Z","shell.execute_reply":"2024-05-14T06:15:11.960559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = \"How do I find a safe place?\"\npipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\nresult = pipe(f\"<s>[INST] {prompt} [/INST]\")\nprint(result[0]['generated_text'])","metadata":{"execution":{"iopub.status.busy":"2024-05-13T09:55:05.614653Z","iopub.execute_input":"2024-05-13T09:55:05.615495Z","iopub.status.idle":"2024-05-13T09:55:22.225170Z","shell.execute_reply.started":"2024-05-13T09:55:05.615459Z","shell.execute_reply":"2024-05-13T09:55:22.224108Z"},"trusted":true},"execution_count":null,"outputs":[]}]}